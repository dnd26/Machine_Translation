{"cells":[{"cell_type":"code","execution_count":1,"id":"5920c1d7","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-11T12:17:48.523149Z","iopub.status.busy":"2023-12-11T12:17:48.522531Z","iopub.status.idle":"2023-12-11T12:18:22.644741Z","shell.execute_reply":"2023-12-11T12:18:22.643383Z"},"papermill":{"duration":34.136345,"end_time":"2023-12-11T12:18:22.647406","exception":false,"start_time":"2023-12-11T12:17:48.511061","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"5920c1d7","executionInfo":{"status":"ok","timestamp":1702353418557,"user_tz":-420,"elapsed":49202,"user":{"displayName":"Huy Dương","userId":"03818274403557308080"}},"outputId":"37e2255d-15d7-42aa-b68e-7be3b7b3fdd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m998.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not install requirement https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz because of HTTP error 404 Client Error: Not Found for url: https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz for URL https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz\u001b[0m\u001b[31m\n","\u001b[0m2023-12-12 03:56:51.172925: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-12 03:56:51.172995: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-12 03:56:51.173028: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-12 03:56:51.182034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-12 03:56:52.483051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[31mDeprecationWarning: The command 'link' is deprecated.\u001b[0m\n","\u001b[38;5;3m⚠ As of spaCy v3.0, model symlinks are not supported anymore. You can\n","load trained pipeline packages using their full names or from a directory\n","path.\u001b[0m\n"]}],"source":["! pip -q install torchtext==0.6.0\n","! pip -q install pyvi\n","! pip -q install https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz\n","! python -m spacy link vi_spacy_model vi_spacy_model"]},{"cell_type":"code","execution_count":2,"id":"8d55323f","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:22.668266Z","iopub.status.busy":"2023-12-11T12:18:22.667844Z","iopub.status.idle":"2023-12-11T12:18:24.191330Z","shell.execute_reply":"2023-12-11T12:18:24.190076Z"},"papermill":{"duration":1.537072,"end_time":"2023-12-11T12:18:24.194138","exception":false,"start_time":"2023-12-11T12:18:22.657066","status":"completed"},"tags":[],"id":"8d55323f","executionInfo":{"status":"ok","timestamp":1702353420858,"user_tz":-420,"elapsed":2306,"user":{"displayName":"Huy Dương","userId":"03818274403557308080"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import numpy as np\n","import os\n","import math\n"]},{"cell_type":"code","execution_count":3,"id":"46a6c0b1","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:24.215263Z","iopub.status.busy":"2023-12-11T12:18:24.214726Z","iopub.status.idle":"2023-12-11T12:18:26.408894Z","shell.execute_reply":"2023-12-11T12:18:26.407844Z"},"papermill":{"duration":2.207228,"end_time":"2023-12-11T12:18:26.411241","exception":false,"start_time":"2023-12-11T12:18:24.204013","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"46a6c0b1","executionInfo":{"status":"ok","timestamp":1702353423266,"user_tz":-420,"elapsed":2412,"user":{"displayName":"Huy Dương","userId":"03818274403557308080"}},"outputId":"62734368-e660-447a-f107-dedfd976ee1f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     /kaggle/working/nltk_data...\n"]}],"source":["import nltk\n","\n","# Specify the download location and download WordNet\n","nltk.download('wordnet', download_dir='/working/nltk_data')\n","nltk.data.path.append('/working/nltk_data')"]},{"cell_type":"code","execution_count":null,"id":"b4e337a3","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.432016Z","iopub.status.busy":"2023-12-11T12:18:26.431638Z","iopub.status.idle":"2023-12-11T12:18:26.437673Z","shell.execute_reply":"2023-12-11T12:18:26.436599Z"},"papermill":{"duration":0.019045,"end_time":"2023-12-11T12:18:26.439653","exception":false,"start_time":"2023-12-11T12:18:26.420608","status":"completed"},"tags":[],"id":"b4e337a3"},"outputs":[],"source":["class Embedder(nn.Module):\n","    def __init__(self, vocab_size, d_model):\n","        super().__init__()\n","        self.vocab_size = vocab_size\n","        self.d_model = d_model\n","\n","        self.embed = nn.Embedding(vocab_size, d_model)\n","\n","    def forward(self, x):\n","        return self.embed(x)\n","\n","# Embedder(100, 512)(torch.LongTensor([1,2,3,4])).shape"]},{"cell_type":"code","execution_count":null,"id":"91e05f42","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.460791Z","iopub.status.busy":"2023-12-11T12:18:26.459851Z","iopub.status.idle":"2023-12-11T12:18:26.470792Z","shell.execute_reply":"2023-12-11T12:18:26.469781Z"},"papermill":{"duration":0.02358,"end_time":"2023-12-11T12:18:26.472880","exception":false,"start_time":"2023-12-11T12:18:26.449300","status":"completed"},"tags":[],"id":"91e05f42"},"outputs":[],"source":["class PositionalEncoder(nn.Module):\n","    def __init__(self, d_model, max_seq_length=200, dropout=0.1):\n","        super().__init__()\n","\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(dropout)\n","\n","        pe = torch.zeros(max_seq_length, d_model)\n","\n","        # Bảng pe mình vẽ ở trên\n","        for pos in range(max_seq_length):\n","            for i in range(0, d_model, 2):\n","                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n","                pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","\n","        x = x*math.sqrt(self.d_model)\n","        seq_length = x.size(1)\n","\n","        pe = Variable(self.pe[:, :seq_length], requires_grad=False)\n","\n","        if x.is_cuda:\n","            pe.cuda()\n","        # cộng embedding vector với pe\n","        x = x + pe\n","        x = self.dropout(x)\n","\n","        return x\n",""]},{"cell_type":"code","execution_count":null,"id":"b1e06d2c","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.493935Z","iopub.status.busy":"2023-12-11T12:18:26.493070Z","iopub.status.idle":"2023-12-11T12:18:26.500405Z","shell.execute_reply":"2023-12-11T12:18:26.499347Z"},"papermill":{"duration":0.020151,"end_time":"2023-12-11T12:18:26.502426","exception":false,"start_time":"2023-12-11T12:18:26.482275","status":"completed"},"tags":[],"id":"b1e06d2c"},"outputs":[],"source":["def attention(q, k, v, mask=None, dropout=None):\n","    \"\"\"\n","    q: batch_size x head x seq_length x d_model\n","    k: batch_size x head x seq_length x d_model\n","    v: batch_size x head x seq_length x d_model\n","    mask: batch_size x 1 x 1 x seq_length\n","    output: batch_size x head x seq_length x d_model\n","    \"\"\"\n","\n","    # attention score được tính bằng cách nhân q với k\n","    d_k = q.size(-1)\n","    scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(d_k)\n","\n","    if mask is not None:\n","        mask = mask.unsqueeze(1)\n","        scores = scores.masked_fill(mask==0, -1e9)\n","    # xong rồi thì chuẩn hóa bằng softmax\n","    scores = F.softmax(scores, dim=-1)\n","\n","    if dropout is not None:\n","        scores = dropout(scores)\n","\n","    output = torch.matmul(scores, v)\n","    return output, scores"]},{"cell_type":"code","execution_count":null,"id":"1e6dd476","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.523129Z","iopub.status.busy":"2023-12-11T12:18:26.522731Z","iopub.status.idle":"2023-12-11T12:18:26.532621Z","shell.execute_reply":"2023-12-11T12:18:26.531463Z"},"papermill":{"duration":0.023084,"end_time":"2023-12-11T12:18:26.534845","exception":false,"start_time":"2023-12-11T12:18:26.511761","status":"completed"},"tags":[],"id":"1e6dd476"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, heads, d_model, dropout=0.1):\n","        super().__init__()\n","        assert d_model % heads == 0\n","\n","        self.d_model = d_model\n","        self.d_k = d_model//heads\n","        self.h = heads\n","        self.attn = None\n","\n","        # tạo ra 3 ma trận trọng số là q_linear, k_linear, v_linear như hình trên\n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.out = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","        \"\"\"\n","        q: batch_size x seq_length x d_model\n","        k: batch_size x seq_length x d_model\n","        v: batch_size x seq_length x d_model\n","        mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","        bs = q.size(0)\n","        # nhân ma trận trọng số q_linear, k_linear, v_linear với dữ liệu đầu vào q, k, v\n","        # ở bước encode các bạn lưu ý rằng q, k, v chỉ là một (xem hình trên)\n","        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n","        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n","        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n","\n","        q = q.transpose(1, 2)\n","        k = k.transpose(1, 2)\n","        v = v.transpose(1, 2)\n","\n","        # tính attention score\n","        scores, self.attn = attention(q, k, v, mask, self.dropout)\n","\n","        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n","\n","        output = self.out(concat)\n","        return output"]},{"cell_type":"code","execution_count":null,"id":"f55fc1b8","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.555863Z","iopub.status.busy":"2023-12-11T12:18:26.555441Z","iopub.status.idle":"2023-12-11T12:18:26.562630Z","shell.execute_reply":"2023-12-11T12:18:26.561521Z"},"papermill":{"duration":0.020382,"end_time":"2023-12-11T12:18:26.564756","exception":false,"start_time":"2023-12-11T12:18:26.544374","status":"completed"},"tags":[],"id":"f55fc1b8"},"outputs":[],"source":["class Norm(nn.Module):\n","    def __init__(self, d_model, eps = 1e-6):\n","        super().__init__()\n","\n","        self.size = d_model\n","\n","        # create two learnable parameters to calibrate normalisation\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n","        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n","        return norm"]},{"cell_type":"code","execution_count":null,"id":"31a07476","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.585119Z","iopub.status.busy":"2023-12-11T12:18:26.584759Z","iopub.status.idle":"2023-12-11T12:18:26.591368Z","shell.execute_reply":"2023-12-11T12:18:26.590332Z"},"papermill":{"duration":0.019289,"end_time":"2023-12-11T12:18:26.593300","exception":false,"start_time":"2023-12-11T12:18:26.574011","status":"completed"},"tags":[],"id":"31a07476"},"outputs":[],"source":["class FeedForward(nn.Module):\n","    \"\"\" Trong kiến trúc của chúng ta có tầng linear\n","    \"\"\"\n","    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n","        super().__init__()\n","\n","        # We set d_ff as a default to 2048\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","\n","    def forward(self, x):\n","        x = self.dropout(F.relu(self.linear_1(x)))\n","        x = self.linear_2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"16e91acf","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.614052Z","iopub.status.busy":"2023-12-11T12:18:26.613656Z","iopub.status.idle":"2023-12-11T12:18:26.621416Z","shell.execute_reply":"2023-12-11T12:18:26.620416Z"},"papermill":{"duration":0.020516,"end_time":"2023-12-11T12:18:26.623584","exception":false,"start_time":"2023-12-11T12:18:26.603068","status":"completed"},"tags":[],"id":"16e91acf"},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.ff = FeedForward(d_model, dropout=dropout)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        \"\"\"\n","        x: batch_size x seq_length x d_model\n","        mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","\n","\n","        x2 = self.norm_1(x)\n","        # tính attention value, các bạn để ý q, k, v là giống nhau\n","        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n","        x2 = self.norm_2(x)\n","        x = x + self.dropout_2(self.ff(x2))\n","        return x\n","\n","# EncoderLayer(512, 8)(torch.rand(32, 30, 512), torch.rand(32 , 1, 30)).shape"]},{"cell_type":"code","execution_count":null,"id":"3ce1fb44","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.644396Z","iopub.status.busy":"2023-12-11T12:18:26.643982Z","iopub.status.idle":"2023-12-11T12:18:26.653328Z","shell.execute_reply":"2023-12-11T12:18:26.652171Z"},"papermill":{"duration":0.022477,"end_time":"2023-12-11T12:18:26.655552","exception":false,"start_time":"2023-12-11T12:18:26.633075","status":"completed"},"tags":[],"id":"3ce1fb44"},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        self.dropout_3 = nn.Dropout(dropout)\n","\n","        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n","        self.ff = FeedForward(d_model, dropout=dropout)\n","\n","    def forward(self, x, e_outputs, src_mask, trg_mask):\n","        \"\"\"\n","        x: batch_size x seq_length x d_model\n","        e_outputs: batch_size x seq_length x d_model\n","        src_mask: batch_size x 1 x seq_length\n","        trg_mask: batch_size x 1 x seq_length\n","        \"\"\"\n","        # Các bạn xem hình trên, kiến trúc mình vẽ với code ở chỗ này tương đương nhau.\n","        x2 = self.norm_1(x)\n","        # multihead attention thứ nhất, chú ý các từ ở target\n","        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n","        x2 = self.norm_2(x)\n","        # masked mulithead attention thứ 2. k, v là giá trị output của mô hình encoder\n","        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n","        x2 = self.norm_3(x)\n","        x = x + self.dropout_3(self.ff(x2))\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"bda4c7ae","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.676077Z","iopub.status.busy":"2023-12-11T12:18:26.675742Z","iopub.status.idle":"2023-12-11T12:18:26.683831Z","shell.execute_reply":"2023-12-11T12:18:26.682824Z"},"papermill":{"duration":0.021234,"end_time":"2023-12-11T12:18:26.686121","exception":false,"start_time":"2023-12-11T12:18:26.664887","status":"completed"},"tags":[],"id":"bda4c7ae"},"outputs":[],"source":["import copy\n","\n","def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n","\n","class Encoder(nn.Module):\n","    \"\"\"Một encoder có nhiều encoder layer nhé !!!\n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model, dropout=dropout)\n","        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","\n","    def forward(self, src, mask):\n","        \"\"\"\n","        src: batch_size x seq_length\n","        mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","        x = self.embed(src)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, mask)\n","        return self.norm(x)"]},{"cell_type":"code","execution_count":null,"id":"e5beef84","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.706438Z","iopub.status.busy":"2023-12-11T12:18:26.706064Z","iopub.status.idle":"2023-12-11T12:18:26.713499Z","shell.execute_reply":"2023-12-11T12:18:26.712568Z"},"papermill":{"duration":0.020071,"end_time":"2023-12-11T12:18:26.715598","exception":false,"start_time":"2023-12-11T12:18:26.695527","status":"completed"},"tags":[],"id":"e5beef84"},"outputs":[],"source":["class Decoder(nn.Module):\n","    \"\"\"Một decoder có nhiều decoder layer nhé !!!\n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model, dropout=dropout)\n","        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, trg, e_outputs, src_mask, trg_mask):\n","        \"\"\"\n","        trg: batch_size x seq_length\n","        e_outputs: batch_size x seq_length x d_model\n","        src_mask: batch_size x 1 x seq_length\n","        trg_mask: batch_size x 1 x seq_length\n","        output: batch_size x seq_length x d_model\n","        \"\"\"\n","        x = self.embed(trg)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n","        return self.norm(x)"]},{"cell_type":"code","execution_count":null,"id":"b4c22342","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.735731Z","iopub.status.busy":"2023-12-11T12:18:26.735384Z","iopub.status.idle":"2023-12-11T12:18:26.742094Z","shell.execute_reply":"2023-12-11T12:18:26.741072Z"},"papermill":{"duration":0.01931,"end_time":"2023-12-11T12:18:26.744012","exception":false,"start_time":"2023-12-11T12:18:26.724702","status":"completed"},"tags":[],"id":"b4c22342"},"outputs":[],"source":["class Transformer(nn.Module):\n","    \"\"\" Cuối cùng ghép chúng lại với nhau để được mô hình transformer hoàn chỉnh\n","    \"\"\"\n","    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n","        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n","        self.out = nn.Linear(d_model, trg_vocab)\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        \"\"\"\n","        src: batch_size x seq_length\n","        trg: batch_size x seq_length\n","        src_mask: batch_size x 1 x seq_length\n","        trg_mask batch_size x 1 x seq_length\n","        output: batch_size x seq_length x vocab_size\n","        \"\"\"\n","        e_outputs = self.encoder(src, src_mask)\n","\n","        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output\n",""]},{"cell_type":"code","execution_count":null,"id":"6ec9d3c1","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.764674Z","iopub.status.busy":"2023-12-11T12:18:26.764311Z","iopub.status.idle":"2023-12-11T12:18:26.847070Z","shell.execute_reply":"2023-12-11T12:18:26.846204Z"},"papermill":{"duration":0.096114,"end_time":"2023-12-11T12:18:26.849450","exception":false,"start_time":"2023-12-11T12:18:26.753336","status":"completed"},"tags":[],"id":"6ec9d3c1"},"outputs":[],"source":["from torchtext import data\n","\n","class MyIterator(data.Iterator):\n","    def create_batches(self):\n","        if self.train:\n","            def pool(d, random_shuffler):\n","                for p in data.batch(d, self.batch_size * 100):\n","                    p_batch = data.batch(\n","                        sorted(p, key=self.sort_key),\n","                        self.batch_size, self.batch_size_fn)\n","                    for b in random_shuffler(list(p_batch)):\n","                        yield b\n","            self.batches = pool(self.data(), self.random_shuffler)\n","\n","        else:\n","            self.batches = []\n","            for b in data.batch(self.data(), self.batch_size,\n","                                          self.batch_size_fn):\n","                self.batches.append(sorted(b, key=self.sort_key))\n","\n","global max_src_in_batch, max_tgt_in_batch\n","\n","def batch_size_fn(new, count, sofar):\n","    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n","    global max_src_in_batch, max_tgt_in_batch\n","    if count == 1:\n","        max_src_in_batch = 0\n","        max_tgt_in_batch = 0\n","    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n","    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n","    src_elements = count * max_src_in_batch\n","    tgt_elements = count * max_tgt_in_batch\n","    return max(src_elements, tgt_elements)"]},{"cell_type":"code","execution_count":null,"id":"eef25a5b","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.871047Z","iopub.status.busy":"2023-12-11T12:18:26.870118Z","iopub.status.idle":"2023-12-11T12:18:26.878314Z","shell.execute_reply":"2023-12-11T12:18:26.877042Z"},"papermill":{"duration":0.021754,"end_time":"2023-12-11T12:18:26.880789","exception":false,"start_time":"2023-12-11T12:18:26.859035","status":"completed"},"tags":[],"id":"eef25a5b"},"outputs":[],"source":["def nopeak_mask(size, device):\n","    \"\"\"Tạo mask được sử dụng trong decoder để lúc dự đoán trong quá trình huấn luyện\n","     mô hình không nhìn thấy được các từ ở tương lai\n","    \"\"\"\n","    np_mask = np.triu(np.ones((1, size, size)),\n","    k=1).astype('uint8')\n","    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n","    np_mask = np_mask.to(device)\n","\n","    return np_mask\n","\n","def create_masks(src, trg, src_pad, trg_pad, device):\n","    \"\"\" Tạo mask cho encoder,\n","    để mô hình không bỏ qua thông tin của các kí tự PAD do chúng ta thêm vào\n","    \"\"\"\n","    src_mask = (src != src_pad).unsqueeze(-2)\n","\n","    if trg is not None:\n","        trg_mask = (trg != trg_pad).unsqueeze(-2)\n","        size = trg.size(1) # get seq_len for matrix\n","        np_mask = nopeak_mask(size, device)\n","        if trg.is_cuda:\n","            np_mask.cuda()\n","        trg_mask = trg_mask & np_mask\n","\n","    else:\n","        trg_mask = None\n","    return src_mask, trg_mask"]},{"cell_type":"code","execution_count":null,"id":"7cab4e6e","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.902092Z","iopub.status.busy":"2023-12-11T12:18:26.901506Z","iopub.status.idle":"2023-12-11T12:18:26.908047Z","shell.execute_reply":"2023-12-11T12:18:26.907134Z"},"papermill":{"duration":0.01996,"end_time":"2023-12-11T12:18:26.910318","exception":false,"start_time":"2023-12-11T12:18:26.890358","status":"completed"},"tags":[],"id":"7cab4e6e"},"outputs":[],"source":["from nltk.corpus import wordnet\n","import re\n","\n","def get_synonym(word, SRC):\n","    syns = wordnet.synsets(word)\n","    for s in syns:\n","        for l in s.lemmas():\n","            if SRC.vocab.stoi[l.name()] != 0:\n","                return SRC.vocab.stoi[l.name()]\n","\n","    return 0\n","\n","def multiple_replace(dict, text):\n","  # Create a regular expression  from the dictionary keys\n","  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n","\n","  # For each match, look-up corresponding value in dictionary\n","  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)"]},{"cell_type":"code","execution_count":null,"id":"095dcc5e","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:26.931169Z","iopub.status.busy":"2023-12-11T12:18:26.930779Z","iopub.status.idle":"2023-12-11T12:18:26.949801Z","shell.execute_reply":"2023-12-11T12:18:26.948655Z"},"papermill":{"duration":0.032289,"end_time":"2023-12-11T12:18:26.951967","exception":false,"start_time":"2023-12-11T12:18:26.919678","status":"completed"},"tags":[],"id":"095dcc5e"},"outputs":[],"source":["def init_vars(src, model, SRC, TRG, device, k, max_len):\n","    \"\"\" Tính toán các ma trận cần thiết trong quá trình translation sau khi mô hình học xong\n","    \"\"\"\n","    init_tok = TRG.vocab.stoi['<sos>']\n","    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n","\n","    # tính sẵn output của encoder\n","    e_output = model.encoder(src, src_mask)\n","\n","    outputs = torch.LongTensor([[init_tok]])\n","\n","    outputs = outputs.to(device)\n","\n","    trg_mask = nopeak_mask(1, device)\n","    # dự đoán kí tự đầu tiên\n","    out = model.out(model.decoder(outputs,\n","    e_output, src_mask, trg_mask))\n","    out = F.softmax(out, dim=-1)\n","\n","    probs, ix = out[:, -1].data.topk(k)\n","    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n","\n","    outputs = torch.zeros(k, max_len).long()\n","    outputs = outputs.to(device)\n","    outputs[:, 0] = init_tok\n","    outputs[:, 1] = ix[0]\n","\n","    e_outputs = torch.zeros(k, e_output.size(-2),e_output.size(-1))\n","\n","    e_outputs = e_outputs.to(device)\n","    e_outputs[:, :] = e_output[0]\n","\n","    return outputs, e_outputs, log_scores\n","\n","def k_best_outputs(outputs, out, log_scores, i, k):\n","\n","    probs, ix = out[:, -1].data.topk(k)\n","    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n","    k_probs, k_ix = log_probs.view(-1).topk(k)\n","\n","    row = k_ix // k\n","    col = k_ix % k\n","\n","    outputs[:, :i] = outputs[row, :i]\n","    outputs[:, i] = ix[row, col]\n","\n","    log_scores = k_probs.unsqueeze(0)\n","\n","    return outputs, log_scores\n","\n","def beam_search(src, model, SRC, TRG, device, k, max_len):\n","\n","    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, device, k, max_len)\n","    eos_tok = TRG.vocab.stoi['<eos>']\n","    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n","    ind = None\n","    for i in range(2, max_len):\n","\n","        trg_mask = nopeak_mask(i, device)\n","\n","        out = model.out(model.decoder(outputs[:,:i],\n","        e_outputs, src_mask, trg_mask))\n","\n","        out = F.softmax(out, dim=-1)\n","\n","        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, k)\n","\n","        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n","        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long)\n","        for vec in ones:\n","            i = vec[0]\n","            if sentence_lengths[i]==0: # First end symbol has not been found yet\n","                sentence_lengths[i] = vec[1] # Position of first end symbol\n","\n","        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n","\n","        if num_finished_sentences == k:\n","            alpha = 0.7\n","            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n","            _, ind = torch.max(log_scores * div, 1)\n","            ind = ind.data[0]\n","            break\n","\n","    if ind is None:\n","\n","        length = (outputs[0]==eos_tok).nonzero()[0] if len((outputs[0]==eos_tok).nonzero()) > 0 else -1\n","        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n","\n","    else:\n","        length = (outputs[ind]==eos_tok).nonzero()[0]\n","        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])"]},{"cell_type":"code","execution_count":null,"id":"6d5ea4a8","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:27.030136Z","iopub.status.busy":"2023-12-11T12:18:27.029073Z","iopub.status.idle":"2023-12-11T12:18:27.035995Z","shell.execute_reply":"2023-12-11T12:18:27.035309Z"},"papermill":{"duration":0.076544,"end_time":"2023-12-11T12:18:27.037981","exception":false,"start_time":"2023-12-11T12:18:26.961437","status":"completed"},"tags":[],"id":"6d5ea4a8"},"outputs":[],"source":["def translate_sentence(sentence, model, SRC, TRG, device, k, max_len):\n","    \"\"\"Dịch một câu sử dụng beamsearch\n","    \"\"\"\n","    model.eval()\n","    indexed = []\n","    sentence = SRC.preprocess(sentence)\n","\n","    for tok in sentence:\n","        if SRC.vocab.stoi[tok] != SRC.vocab.stoi['<eos>']:\n","            indexed.append(SRC.vocab.stoi[tok])\n","        else:\n","            indexed.append(get_synonym(tok, SRC))\n","\n","    sentence = Variable(torch.LongTensor([indexed]))\n","\n","    sentence = sentence.to(device)\n","\n","    sentence = beam_search(sentence, model, SRC, TRG, device, k, max_len)\n","\n","    return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)"]},{"cell_type":"code","execution_count":null,"id":"0496b3be","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:27.059715Z","iopub.status.busy":"2023-12-11T12:18:27.058836Z","iopub.status.idle":"2023-12-11T12:18:27.911722Z","shell.execute_reply":"2023-12-11T12:18:27.910589Z"},"papermill":{"duration":0.866687,"end_time":"2023-12-11T12:18:27.914365","exception":false,"start_time":"2023-12-11T12:18:27.047678","status":"completed"},"tags":[],"id":"0496b3be"},"outputs":[],"source":["import spacy\n","import re\n","\n","class tokenize(object):\n","\n","    def __init__(self, lang):\n","        if lang == 'en':\n","            self.nlp = spacy.load(\"en_core_web_sm\")\n","        else:\n","            self.nlp = spacy.load(lang)\n","\n","    def tokenizer(self, sentence):\n","        sentence = re.sub(\n","        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n","        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n","        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n","        sentence = re.sub(r\"\\,+\", \",\", sentence)\n","        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n","        sentence = sentence.lower()\n","        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"]},{"cell_type":"code","execution_count":null,"id":"1302fc2b","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:27.936209Z","iopub.status.busy":"2023-12-11T12:18:27.934836Z","iopub.status.idle":"2023-12-11T12:18:28.409240Z","shell.execute_reply":"2023-12-11T12:18:28.408295Z"},"papermill":{"duration":0.487696,"end_time":"2023-12-11T12:18:28.411734","exception":false,"start_time":"2023-12-11T12:18:27.924038","status":"completed"},"tags":[],"id":"1302fc2b"},"outputs":[],"source":["import os\n","import dill as pickle\n","import pandas as pd\n","\n","def read_data(src_file, trg_file):\n","    src_data = open(src_file).read().strip().split('\\n')\n","\n","    trg_data = open(trg_file).read().strip().split('\\n')\n","\n","    return src_data, trg_data\n","\n","def create_fields(src_lang, trg_lang):\n","\n","    print(\"loading spacy tokenizers...\")\n","\n","    t_src = tokenize(src_lang)\n","    t_trg = tokenize(trg_lang)\n","\n","    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n","    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n","\n","    return SRC, TRG\n","\n","def create_dataset(src_data, trg_data, max_strlen, batchsize, device, SRC, TRG, istrain=True):\n","\n","    print(\"creating dataset and iterator... \")\n","\n","    raw_data = {'src' : [line for line in src_data], 'trg': [line for line in trg_data]}\n","    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n","\n","    mask = (df['src'].str.count(' ') < max_strlen) & (df['trg'].str.count(' ') < max_strlen)\n","    df = df.loc[mask]\n","\n","    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n","\n","    data_fields = [('src', SRC), ('trg', TRG)]\n","    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n","\n","    train_iter = MyIterator(train, batch_size=batchsize, device=device,\n","                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n","                        batch_size_fn=batch_size_fn, train=istrain, shuffle=True)\n","\n","    os.remove('translate_transformer_temp.csv')\n","\n","    if istrain:\n","        SRC.build_vocab(train)\n","        TRG.build_vocab(train)\n","\n","    return train_iter"]},{"cell_type":"code","execution_count":null,"id":"c114b0cb","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.432441Z","iopub.status.busy":"2023-12-11T12:18:28.431846Z","iopub.status.idle":"2023-12-11T12:18:28.439595Z","shell.execute_reply":"2023-12-11T12:18:28.438537Z"},"papermill":{"duration":0.020293,"end_time":"2023-12-11T12:18:28.441604","exception":false,"start_time":"2023-12-11T12:18:28.421311","status":"completed"},"tags":[],"id":"c114b0cb"},"outputs":[],"source":["def step(model, optimizer,batch, criterion):\n","    \"\"\"\n","    Một lần cập nhật mô hình\n","    \"\"\"\n","    model.train()\n","\n","    src = batch.src.transpose(0,1)\n","    trg = batch.trg.transpose(0,1)\n","    trg_input = trg[:, :-1]\n","    src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n","    preds = model(src, trg_input, src_mask, trg_mask)\n","\n","    ys = trg[:, 1:].contiguous().view(-1)\n","\n","    optimizer.zero_grad()\n","    loss = criterion(preds.view(-1, preds.size(-1)), ys)\n","    loss.backward()\n","    optimizer.step_and_update_lr()\n","\n","    loss = loss.item()\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"id":"f71ef3d6","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.462121Z","iopub.status.busy":"2023-12-11T12:18:28.461542Z","iopub.status.idle":"2023-12-11T12:18:28.468526Z","shell.execute_reply":"2023-12-11T12:18:28.467368Z"},"papermill":{"duration":0.020629,"end_time":"2023-12-11T12:18:28.471559","exception":false,"start_time":"2023-12-11T12:18:28.450930","status":"completed"},"tags":[],"id":"f71ef3d6"},"outputs":[],"source":["def validiate(model, valid_iter, criterion):\n","    \"\"\" Tính loss trên tập validation\n","    \"\"\"\n","    model.eval()\n","\n","    with torch.no_grad():\n","        total_loss = []\n","        for batch in valid_iter:\n","            src = batch.src.transpose(0,1)\n","            trg = batch.trg.transpose(0,1)\n","            trg_input = trg[:, :-1]\n","            src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n","            preds = model(src, trg_input, src_mask, trg_mask)\n","\n","            ys = trg[:, 1:].contiguous().view(-1)\n","\n","            loss = criterion(preds.view(-1, preds.size(-1)), ys)\n","\n","            loss = loss.item()\n","\n","            total_loss.append(loss)\n","\n","    avg_loss = np.mean(total_loss)\n","\n","    return avg_loss"]},{"cell_type":"code","execution_count":null,"id":"17a7662e","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.492373Z","iopub.status.busy":"2023-12-11T12:18:28.491761Z","iopub.status.idle":"2023-12-11T12:18:28.502443Z","shell.execute_reply":"2023-12-11T12:18:28.501293Z"},"papermill":{"duration":0.023456,"end_time":"2023-12-11T12:18:28.504694","exception":false,"start_time":"2023-12-11T12:18:28.481238","status":"completed"},"tags":[],"id":"17a7662e"},"outputs":[],"source":["class ScheduledOptim():\n","    '''A simple wrapper class for learning rate scheduling'''\n","\n","    def __init__(self, optimizer, init_lr, d_model, n_warmup_steps):\n","        self._optimizer = optimizer\n","        self.init_lr = init_lr\n","        self.d_model = d_model\n","        self.n_warmup_steps = n_warmup_steps\n","        self.n_steps = 0\n","\n","\n","    def step_and_update_lr(self):\n","        \"Step with the inner optimizer\"\n","        self._update_learning_rate()\n","        self._optimizer.step()\n","\n","\n","    def zero_grad(self):\n","        \"Zero out the gradients with the inner optimizer\"\n","        self._optimizer.zero_grad()\n","\n","\n","    def _get_lr_scale(self):\n","        d_model = self.d_model\n","        n_steps, n_warmup_steps = self.n_steps, self.n_warmup_steps\n","        return (d_model ** -0.5) * min(n_steps ** (-0.5), n_steps * n_warmup_steps ** (-1.5))\n","\n","    def state_dict(self):\n","        optimizer_state_dict = {\n","            'init_lr':self.init_lr,\n","            'd_model':self.d_model,\n","            'n_warmup_steps':self.n_warmup_steps,\n","            'n_steps':self.n_steps,\n","            '_optimizer':self._optimizer.state_dict(),\n","        }\n","\n","        return optimizer_state_dict\n","\n","    def load_state_dict(self, state_dict):\n","        self.init_lr = state_dict['init_lr']\n","        self.d_model = state_dict['d_model']\n","        self.n_warmup_steps = state_dict['n_warmup_steps']\n","        self.n_steps = state_dict['n_steps']\n","\n","        self._optimizer.load_state_dict(state_dict['_optimizer'])\n","\n","    def _update_learning_rate(self):\n","        ''' Learning rate scheduling per step '''\n","\n","        self.n_steps += 1\n","        lr = self.init_lr * self._get_lr_scale()\n","\n","        for param_group in self._optimizer.param_groups:\n","            param_group['lr'] = lr"]},{"cell_type":"code","execution_count":null,"id":"4cfc6b99","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.525856Z","iopub.status.busy":"2023-12-11T12:18:28.524968Z","iopub.status.idle":"2023-12-11T12:18:28.792488Z","shell.execute_reply":"2023-12-11T12:18:28.791461Z"},"papermill":{"duration":0.280626,"end_time":"2023-12-11T12:18:28.794973","exception":false,"start_time":"2023-12-11T12:18:28.514347","status":"completed"},"tags":[],"id":"4cfc6b99"},"outputs":[],"source":["import zipfile\n","import os\n","\n","def extract_zip(zip_file_path, extract_to_path):\n","    \"\"\"\n","    Giải nén một file zip vào một thư mục.\n","\n","    Parameters:\n","    - zip_file_path: Đường dẫn đến file zip.\n","    - extract_to_path: Đường dẫn đến thư mục nơi bạn muốn giải nén nội dung của file zip.\n","\n","    Returns:\n","    - Không có giá trị trả về. Hàm này chỉ thực hiện việc giải nén.\n","    \"\"\"\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to_path)\n","\n","# Ví dụ sử dụng hàm:\n","zip_file_path = '/kaggle/working/nltk_data/corpora/wordnet.zip'\n","extract_to_path = '/kaggle/working/nltk_data/corpora/'\n","extract_zip(zip_file_path, extract_to_path)\n"]},{"cell_type":"code","execution_count":null,"id":"2a094618","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.815525Z","iopub.status.busy":"2023-12-11T12:18:28.814855Z","iopub.status.idle":"2023-12-11T12:18:28.823220Z","shell.execute_reply":"2023-12-11T12:18:28.822275Z"},"papermill":{"duration":0.020636,"end_time":"2023-12-11T12:18:28.825228","exception":false,"start_time":"2023-12-11T12:18:28.804592","status":"completed"},"tags":[],"id":"2a094618"},"outputs":[],"source":["class LabelSmoothingLoss(nn.Module):\n","    def __init__(self, classes, padding_idx, smoothing=0.0, dim=-1):\n","        super(LabelSmoothingLoss, self).__init__()\n","        self.confidence = 1.0 - smoothing\n","        self.smoothing = smoothing\n","        self.cls = classes\n","        self.dim = dim\n","        self.padding_idx = padding_idx\n","\n","    def forward(self, pred, target):\n","        pred = pred.log_softmax(dim=self.dim)\n","        with torch.no_grad():\n","            # true_dist = pred.data.clone()\n","            true_dist = torch.zeros_like(pred)\n","            true_dist.fill_(self.smoothing / (self.cls - 2))\n","            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","            true_dist[:, self.padding_idx] = 0\n","            mask = torch.nonzero(target.data == self.padding_idx, as_tuple=False)\n","            if mask.dim() > 0:\n","                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n","\n","        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"]},{"cell_type":"code","execution_count":null,"id":"bbf65621","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.845653Z","iopub.status.busy":"2023-12-11T12:18:28.844855Z","iopub.status.idle":"2023-12-11T12:18:28.851271Z","shell.execute_reply":"2023-12-11T12:18:28.850315Z"},"papermill":{"duration":0.018552,"end_time":"2023-12-11T12:18:28.853257","exception":false,"start_time":"2023-12-11T12:18:28.834705","status":"completed"},"tags":[],"id":"bbf65621"},"outputs":[],"source":["from torchtext.data.metrics import bleu_score\n","\n","def bleu(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen):\n","    pred_sents = []\n","    for sentence in valid_src_data:\n","        pred_trg = translate_sentence(sentence, model, SRC, TRG, device, k, max_strlen)\n","        pred_sents.append(pred_trg)\n","\n","    pred_sents = [TRG.preprocess(sent) for sent in pred_sents]\n","    trg_sents = [[sent.split()] for sent in valid_trg_data]\n","\n","    return bleu_score(pred_sents, trg_sents)"]},{"cell_type":"code","execution_count":null,"id":"7e0b9d30","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.873654Z","iopub.status.busy":"2023-12-11T12:18:28.873296Z","iopub.status.idle":"2023-12-11T12:18:28.878902Z","shell.execute_reply":"2023-12-11T12:18:28.877914Z"},"papermill":{"duration":0.018257,"end_time":"2023-12-11T12:18:28.881023","exception":false,"start_time":"2023-12-11T12:18:28.862766","status":"completed"},"tags":[],"id":"7e0b9d30"},"outputs":[],"source":["opt = {\n","    'train_src_data':'/kaggle/input/en-to-vi/train.en',\n","    'train_trg_data':'/kaggle/input/en-to-vi/train.vi',\n","    'valid_src_data':'/kaggle/input/en-to-vi/tst2013.en',\n","    'valid_trg_data':'/kaggle/input/en-to-vi/tst2013.vi',\n","    'src_lang':'en',\n","    'trg_lang':'en',#'vi_spacy_model',\n","    'max_strlen':160,\n","    'batchsize':1500,\n","    'device':'cpu',\n","    'd_model': 512,\n","    'n_layers': 6,\n","    'heads': 8,\n","    'dropout': 0.1,\n","    'lr':0.0001,\n","    'epochs':10,\n","    'printevery': 200,\n","    'k':5,\n","}"]},{"cell_type":"code","execution_count":null,"id":"c34d0644","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:28.901999Z","iopub.status.busy":"2023-12-11T12:18:28.901646Z","iopub.status.idle":"2023-12-11T12:18:35.768306Z","shell.execute_reply":"2023-12-11T12:18:35.767092Z"},"papermill":{"duration":6.880275,"end_time":"2023-12-11T12:18:35.771097","exception":false,"start_time":"2023-12-11T12:18:28.890822","status":"completed"},"tags":[],"id":"c34d0644","outputId":"de1d6a52-7a9d-4d18-a9e2-5df78e387e4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading spacy tokenizers...\n","creating dataset and iterator... \n","creating dataset and iterator... \n"]}],"source":["train_src_data, train_trg_data = read_data(opt['train_src_data'], opt['train_trg_data'])\n","valid_src_data, valid_trg_data = read_data(opt['valid_src_data'], opt['valid_trg_data'])\n","\n","SRC, TRG = create_fields(opt['src_lang'], opt['trg_lang'])\n","\n","train_src_data = [t.replace('&apos;m', 'am')\n","               .replace('&apos;re', 'are')\n","               .replace('&apos;s', 'is')\n","               .replace('&apos;ve', 'have')\n","               .replace('&apos;ll', 'will')\n","               .replace('don &apos;t', 'do not')\n","               .replace('didn &apos;t', 'did not')\n","               .replace('Don &apos;t', 'Do not')\n","               .replace('Didn &apos;t', 'Did not')\n","               for t in train_src_data]\n","\n","train_trg_data = [t.replace('đ', 'd')\n","              .replace('Đ', 'D')\n","              .replace(\"&#93\", \"\")\n","              .replace(\"&#91\", \"\")\n","              .replace(';', ',')\n","              for t in train_trg_data]\n","\n","valid_trg_data = [t.replace('đ', 'd')\n","              .replace('Đ', 'D')\n","              .replace(\"&#93\", \"\")\n","              .replace(\"&#91\", \"\")\n","              .replace(';', ',')\n","              for t in valid_trg_data]\n","\n","\n","valid_src_data = [t.replace('&apos;m', 'am')\n","               .replace('&apos;re', 'are')\n","               .replace('&apos;s', 'is')\n","               .replace('&apos;ve', 'have')\n","               .replace('&apos;ll', 'will')\n","               .replace('don &apos;t', 'do not')\n","               .replace('didn &apos;t', 'did not')\n","               .replace('Don &apos;t', 'Do not')\n","               .replace('Didn &apos;t', 'Did not')\n","               for t in valid_src_data]\n","\n","\n","\n","train_iter = create_dataset(train_src_data[:10000], train_trg_data[:10000], opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=True)\n","valid_iter = create_dataset(valid_src_data[:10000], valid_trg_data[:10000], opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=False)\n"]},{"cell_type":"code","execution_count":null,"id":"47d31dab","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:35.791954Z","iopub.status.busy":"2023-12-11T12:18:35.791598Z","iopub.status.idle":"2023-12-11T12:18:35.795799Z","shell.execute_reply":"2023-12-11T12:18:35.795033Z"},"papermill":{"duration":0.016701,"end_time":"2023-12-11T12:18:35.797622","exception":false,"start_time":"2023-12-11T12:18:35.780921","status":"completed"},"tags":[],"id":"47d31dab"},"outputs":[],"source":["src_pad = SRC.vocab.stoi['<pad>']\n","trg_pad = TRG.vocab.stoi['<pad>']"]},{"cell_type":"code","execution_count":null,"id":"bbd71a31","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:35.818737Z","iopub.status.busy":"2023-12-11T12:18:35.818340Z","iopub.status.idle":"2023-12-11T12:18:38.112368Z","shell.execute_reply":"2023-12-11T12:18:38.111340Z"},"papermill":{"duration":2.30761,"end_time":"2023-12-11T12:18:38.114863","exception":false,"start_time":"2023-12-11T12:18:35.807253","status":"completed"},"tags":[],"id":"bbd71a31"},"outputs":[],"source":["model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"92949e96","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:38.135991Z","iopub.status.busy":"2023-12-11T12:18:38.135605Z","iopub.status.idle":"2023-12-11T12:18:38.143788Z","shell.execute_reply":"2023-12-11T12:18:38.142704Z"},"papermill":{"duration":0.021111,"end_time":"2023-12-11T12:18:38.145881","exception":false,"start_time":"2023-12-11T12:18:38.124770","status":"completed"},"tags":[],"id":"92949e96","outputId":"69c6483e-9d1e-4be2-8af7-cea90ee9b964"},"outputs":[{"data":{"text/plain":["(12282, 5281)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["len(SRC.vocab), len(TRG.vocab)"]},{"cell_type":"code","execution_count":null,"id":"ad153e42","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:38.167424Z","iopub.status.busy":"2023-12-11T12:18:38.166695Z","iopub.status.idle":"2023-12-11T12:18:38.173942Z","shell.execute_reply":"2023-12-11T12:18:38.172993Z"},"papermill":{"duration":0.020237,"end_time":"2023-12-11T12:18:38.176003","exception":false,"start_time":"2023-12-11T12:18:38.155766","status":"completed"},"tags":[],"id":"ad153e42"},"outputs":[],"source":["optimizer = ScheduledOptim(\n","        torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n","        0.2, opt['d_model'], 4000)\n","\n","criterion = LabelSmoothingLoss(len(TRG.vocab), padding_idx=trg_pad, smoothing=0.1)"]},{"cell_type":"code","execution_count":null,"id":"84018113","metadata":{"execution":{"iopub.execute_input":"2023-12-11T12:18:38.199000Z","iopub.status.busy":"2023-12-11T12:18:38.198201Z","iopub.status.idle":"2023-12-11T14:22:39.091435Z","shell.execute_reply":"2023-12-11T14:22:39.089913Z"},"papermill":{"duration":7440.919971,"end_time":"2023-12-11T14:22:39.105942","exception":false,"start_time":"2023-12-11T12:18:38.185971","status":"completed"},"tags":[],"id":"84018113","outputId":"5e6e0c70-0816-4259-864a-9a248584c1cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 000 - iter: 00199 - train loss: 6.9680 - time: 3.6578\n","epoch: 000 - iter: 00213 - valid loss: 5.6950 - time: 35.3624\n","epoch: 001 - iter: 00199 - train loss: 6.2435 - time: 4.0556\n","epoch: 001 - iter: 00213 - valid loss: 5.0693 - time: 34.6909\n","epoch: 002 - iter: 00199 - train loss: 5.5983 - time: 3.2307\n","epoch: 002 - iter: 00213 - valid loss: 4.7445 - time: 34.7804\n","epoch: 003 - iter: 00199 - train loss: 5.3246 - time: 3.5197\n","epoch: 003 - iter: 00213 - valid loss: 4.5789 - time: 36.2665\n","epoch: 004 - iter: 00199 - train loss: 5.1825 - time: 3.3422\n","epoch: 004 - iter: 00213 - valid loss: 4.4421 - time: 34.9928\n","epoch: 005 - iter: 00199 - train loss: 4.9975 - time: 3.4324\n","epoch: 005 - iter: 00213 - valid loss: 4.3060 - time: 35.2667\n","epoch: 006 - iter: 00199 - train loss: 4.7835 - time: 3.4396\n","epoch: 006 - iter: 00213 - valid loss: 4.2117 - time: 35.2426\n","epoch: 007 - iter: 00199 - train loss: 4.6127 - time: 2.7851\n","epoch: 007 - iter: 00213 - valid loss: 4.0884 - time: 35.7615\n","epoch: 008 - iter: 00199 - train loss: 4.4651 - time: 3.0864\n","epoch: 008 - iter: 00213 - valid loss: 3.9932 - time: 35.6314\n","epoch: 009 - iter: 00199 - train loss: 4.3499 - time: 3.9243\n","epoch: 009 - iter: 00213 - valid loss: 3.9324 - time: 35.6753\n"]}],"source":["import time\n","\n","for epoch in range(opt['epochs']):\n","    total_loss = 0\n","\n","    for i, batch in enumerate(train_iter):\n","        s = time.time()\n","        loss = step(model, optimizer, batch, criterion)\n","\n","        total_loss += loss\n","\n","        if (i + 1) % opt['printevery'] == 0:\n","            avg_loss = total_loss/opt['printevery']\n","            print('epoch: {:03d} - iter: {:05d} - train loss: {:.4f} - time: {:.4f}'.format(epoch, i, avg_loss, time.time()- s))\n","            total_loss = 0\n","\n","    s = time.time()\n","    valid_loss = validiate(model, valid_iter, criterion)\n","#     bleuscore = bleu(valid_src_data[:50], valid_trg_data[:50], model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","    print('epoch: {:03d} - iter: {:05d} - valid loss: {:.4f} - time: {:.4f}'.format(epoch, i, valid_loss, time.time() - s))\n",""]},{"cell_type":"code","execution_count":null,"id":"d93c05f8","metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:22:39.131714Z","iopub.status.busy":"2023-12-11T14:22:39.131005Z","iopub.status.idle":"2023-12-11T14:22:41.963095Z","shell.execute_reply":"2023-12-11T14:22:41.961781Z"},"papermill":{"duration":2.847657,"end_time":"2023-12-11T14:22:41.965521","exception":false,"start_time":"2023-12-11T14:22:39.117864","status":"completed"},"tags":[],"id":"d93c05f8","outputId":"4a3f2745-43e3-4750-df4c-78d8f0264575"},"outputs":[{"data":{"text/plain":["'và tôi không phải là, tôi không phải là tôi không phải là người.'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["sentence='My family was not poor , and myself , I had never experienced hunger .'\n","trans_sent = translate_sentence(sentence, model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","trans_sent"]},{"cell_type":"code","execution_count":null,"id":"a038e732","metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:22:41.990846Z","iopub.status.busy":"2023-12-11T14:22:41.990438Z","iopub.status.idle":"2023-12-11T14:22:42.282425Z","shell.execute_reply":"2023-12-11T14:22:42.281364Z"},"papermill":{"duration":0.307473,"end_time":"2023-12-11T14:22:42.284857","exception":false,"start_time":"2023-12-11T14:22:41.977384","status":"completed"},"tags":[],"id":"a038e732"},"outputs":[],"source":["torch.save(model, '/kaggle/working/model_translator.pt')"]},{"cell_type":"code","execution_count":null,"id":"9904138e","metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:22:42.310329Z","iopub.status.busy":"2023-12-11T14:22:42.309938Z","iopub.status.idle":"2023-12-11T14:22:42.409701Z","shell.execute_reply":"2023-12-11T14:22:42.408511Z"},"papermill":{"duration":0.115719,"end_time":"2023-12-11T14:22:42.412137","exception":false,"start_time":"2023-12-11T14:22:42.296418","status":"completed"},"tags":[],"id":"9904138e","outputId":"28ccbe15-9360-4a25-fa18-927743dc2b90"},"outputs":[{"data":{"text/plain":["Transformer(\n","  (encoder): Encoder(\n","    (embed): Embedder(\n","      (embed): Embedding(12282, 512)\n","    )\n","    (pe): PositionalEncoder(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layers): ModuleList(\n","      (0-5): 6 x EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): Decoder(\n","    (embed): Embedder(\n","      (embed): Embedding(5281, 512)\n","    )\n","    (pe): PositionalEncoder(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layers): ModuleList(\n","      (0-5): 6 x DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=5281, bias=True)\n",")"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["model_1 = torch.load('/kaggle/working/model_translator.pt')\n","model_1.eval()"]},{"cell_type":"code","execution_count":null,"id":"b03dcae4","metadata":{"execution":{"iopub.execute_input":"2023-12-11T14:22:42.439952Z","iopub.status.busy":"2023-12-11T14:22:42.439532Z","iopub.status.idle":"2023-12-11T14:22:42.669724Z","shell.execute_reply":"2023-12-11T14:22:42.668464Z"},"papermill":{"duration":0.247151,"end_time":"2023-12-11T14:22:42.671666","exception":false,"start_time":"2023-12-11T14:22:42.424515","status":"completed"},"tags":[],"id":"b03dcae4","outputId":"b834ecc2-5fe1-49aa-b639-2c2a8ff8196e"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 438 ms, sys: 2.98 ms, total: 441 ms\n","Wall time: 223 ms\n"]},{"data":{"text/plain":["'bạn sẽ làm diều gì.'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","sentence='what are you doing'\n","trans_sent = translate_sentence(sentence, model_1, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n","trans_sent"]},{"cell_type":"code","execution_count":null,"id":"439b2587","metadata":{"papermill":{"duration":0.01127,"end_time":"2023-12-11T14:22:42.694950","exception":false,"start_time":"2023-12-11T14:22:42.683680","status":"completed"},"tags":[],"id":"439b2587"},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4141009,"sourceId":7167930,"sourceType":"datasetVersion"},{"datasetId":4141198,"sourceId":7168178,"sourceType":"datasetVersion"}],"dockerImageVersionId":30615,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":7500.046028,"end_time":"2023-12-11T14:22:45.578640","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-11T12:17:45.532612","version":"2.4.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}